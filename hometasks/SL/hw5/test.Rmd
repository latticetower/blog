mnist
========

Пробовала deskewing, не похоже, что сильно помогло. Пробовала применять фильтры. Стало еще медленней и результаты ухудшились.

Затем мне надоело, что приходится подолгу дожидаться результатов, и я решила обрезать края у цифр и центрировать сами цифры, чтобы сократить количество предикторов и время вычислений. На полученном датасете результаты ухудшились не сильно (точность предсказания осталась на уровне примерно 4%), поэтому решила дальше работать именно с таким, обработанным набором данных. Код, который использовала для обработки:

[Обработчик 1](preprocessor.R)

Результаты deskewing и фильтров не сильно улучшились. Тут я подумала, что имеет смысл добавить немного своих предикторов. А начать с очень простого соображения: что мы знаем про цифры? - у некоторых есть кружочки, у некоторых нет (даже в разных формах написания). Поэтому я посчитала для всех цифр количество связных областей на картинке, не окрашенных в какой-либо цвет (при этом фон картинки справа считается связным с фоном картинки слева, аналогично сверху и снизу):

[Обработчик 2](preprocessor_2.R)

для определения связных участков использовала простой рекурсивный алгоритм заливки контура (раскрашивала найденную область ненулевым цветом и увеличивала счетчик связных областей на 1).

Следующая идея - поворачивать циферки так, чтобы они были максимально "узкими". Это поможет выровнять все 1 (пока не реализовано)

```{r}
rm(list = ls(all.names = TRUE))
library(e1071)
library(MASS)
library(raster)
library(data.table)

source("PCA/PCAfncs.R")
source("mnist.r") # http://yann.lecun.com/exdb/mnist/

train <- load_image_file2('mnist/train-data.changed')
train$y <- load_label_file('mnist/train-labels.changed')
train$cc <- load_label_file('mnist/train-data.connected.comp')
train$weight <- load_label_file('mnist/train-data.weight')
train$wx <- load_label_file('mnist/train-data.weight.x')
train$wy <- load_label_file('mnist/train-data.weight.y')


mnist.train <-data.frame(y=train$y, c=train$cc, w=train$weight, wx=train$wx, wy=train$wy, x=train$x)

test<- load_image_file2('mnist/test-data.changed')
test$y <- load_label_file('mnist/test-labels.changed')
test$cc <- load_label_file('mnist/test-data.connected.comp')
test$weight <- load_label_file('mnist/test-data.weight')
test$wx <- load_label_file('mnist/test-data.weight.x')
test$wy <- load_label_file('mnist/test-data.weight.y')


mnist.test <- data.frame(y=test$y, c=test$cc, w=test$weight, wx=test$wx, wy=test$wy, x=test$x) 

maxwidth <- max(train$ncol, test$ncol)
maxheight <- max(train$nrow, test$nrow)

mnist.train$y <- factor(mnist.train$y)
#mnist.train$c <- factor(mnist.train$c)

mnist.test$y <- factor(mnist.test$y)
#mnist.test$c <- factor(mnist.test$c)


deskew <- function(df, mincol=1, maxcol=ncol(df), threshold=2) {
  for (i in mincol:maxcol) {
    t <- log(1 + df[,i] - min(df[,i]))[, 1]
    if (is.nan(skewness(t, na.rm=TRUE)))
      next 
    if (abs(skewness(df[,i], na.rm=TRUE)) > threshold * abs(skewness(t, na.rm=TRUE)))
      df[,i] <- t
  }
  df
}
pcalda <- function(...) pcawrap(lda, ...)
predict.pcalda <- function(...) predict(...)$class
show_digit <- function(arr784, col = gray(12:1/12), ...) {
    image(matrix(arr784, nrow = maxheight)[, maxheight:1], col = col, ...)
}

#for (i in 1:nrow(mnist.train)) {
#  r <- raster(matrix(t(mnist.train[i, -1]), nrow = 28))
#  r3 <- focal(r, w=matrix(1/9,nrow=3,ncol=3))
#  mm <- as.matrix(r3)
#  mm[is.na(mm)]<-0
#  mnist.train[i, -1] <- mm
#}


#for (i in 1:nrow(mnist.test)) {
#  r <- raster(matrix(t(mnist.test[i, -1]), nrow = 28))
#  r3 <- focal(r, w=matrix(1/9,nrow=3,ncol=3))
#  mm <- as.matrix(r3)
#  mm[is.na(mm)]<-0
#  mnist.test[i, -1] <- as.matrix(r3)
#}
```

```{r}

show_digit(as.matrix(mnist.train[1, -c(1:5)]), main = mnist.train[1, 1])
show_digit(as.matrix(mnist.train[2, -c(1:5)]), main = mnist.train[2, 1])
show_digit(as.matrix(mnist.train[11, -c(1:5)]), main = mnist.train[11, 1])

#sds <- sapply(mnist.train, sd)
#zero.sd <- names(mnist.train)[sds < 2 ]
mnist.train.nz <- mnist.train #[, setdiff(names(mnist.train), zero.sd)]

#sds2 <- sapply(mnist.train.nz, sd)
#zero.sd2 <- names(mnist.train.nz)[sds2 < 2 ][-1]
#mnist.train.nz2 <- mnist.train.nz[, setdiff(names(mnist.train.nz), zero.sd2)]
#mnist.train.nz <- mnist.train.nz2 

#mnist.train.nz <- deskew(mnist.train.nz, mincol=3)

#sds2 <- sapply(mnist.train.nz, sd)
#zero.sd2 <- names(mnist.train.nz)[(sds2) <= 2]
#mnist.train.nz <- mnist.train.nz [, setdiff(names(mnist.train.nz), zero.sd2)]
```

```{r }
mnist.train.nz.jittered <- mnist.train.nz
mnist.train.nz.jittered[, -c(1:5)] <- apply(mnist.train.nz[, -c(1:5)], 2, jitter)

tn.lda <- tune(lda, y ~ ., data = mnist.train.nz,
               predict.func = predict.pcalda, tunecontrol = tune.control(cross = 3))
summary(tn.lda)
table(actual = mnist.train$y, predicted = predict(tn.lda$best.model, mnist.train)$class)

tt <- table(actual = mnist.test$y, predicted = predict(tn.lda$best.model,
                                                       mnist.test)$class)
print(tt)

1 - sum(diag(tt))/sum(tt)
```

```{r}
#zero.sd <- names(mnist.train)[sds < 2]
#mnist.train.nz <- mnist.train[, setdiff(names(mnist.train), zero.sd)]
#mnist.train.nz<- deskew(mnist.train.nz, mincol=2)
pcaqda <- function(...) pcawrap(qda, ...)
predict.pcaqda <- function(...) predict(...)$class

```
```{r}

tn.qda <- tune(qda, y ~ ., data = mnist.train.nz.jittered,
               predict.func = predict.pcaqda,
               tunecontrol = tune.control(cross = 2))

summary(tn.qda)
table(actual = mnist.train$y,
      predicted = predict(tn.qda$best.model)$class)
tt <- table(actual = mnist.test$y,
            predicted = predict(tn.qda$best.model, mnist.test)$class)
print(tt)
1 - sum(diag(tt)) / sum(tt)

```
```{r}
conn.comps <- levels(factor(mnist.train.nz[,"c"]))

pcaqda_array <- NULL
#digits <- levels(factor(mnist.train.nz[mnist.train.nz[, "c"] == conn.comps[6], ][, 1]))
#nrow(mnist.train.nz[ is.element(mnist.train.nz[, "y"], digits), ])
k<-1
for (i in 1 : length(conn.comps)) {
  digits <- levels(factor(mnist.train.nz[mnist.train.nz[, "c"] == conn.comps[i], ][, 1]))
  print(digits)
  #mnist.train.nz.filtered <- mnist.train.nz[ is.element(mnist.train.nz[, "y"], digits), ]
  mnist.train.nz.filtered <- mnist.train.nz[ mnist.train.nz[, "c"]==conn.comps[i], ]
  
  tn.pcaqda_temp <- tune(pcaqda, y ~ .-c, data = mnist.train.nz.filtered,
                  scale = FALSE, center = TRUE,# ranges = list(ncomp = c(1, 10, 20, 40, 50)),
                  ranges = list(ncomp = c(10, 30, 35, 40, 50, 70, 90)),
                  predict.func = predict.pcaqda,
                  tunecontrol = tune.control(cross = 3))
  #print(tn.pcaqda_temp)
  if (!is.null(tn.pcaqda_temp)) {
    pcaqda_array <- cbind(pcaqda_array, tn.pcaqda_temp)
    colnames(pcaqda_array)[k] <- conn.comps[i]
    k<- k+1
  }

}
print(ncol(pcaqda_array))
print(conn.comps)
tn.pcaqda <- tune(pcaqda, y ~ ., data = mnist.train.nz,
                  scale = FALSE, center = TRUE,# ranges = list(ncomp = c(1, 10, 20, 40, 50)),
                  ranges = list(ncomp = c(10, 30, 35, 40, 50, 70, 90)),
                  predict.func = predict.pcaqda,
                  tunecontrol = tune.control(cross = 3))

#summary(tn.pcaqda)
#method returns set of predicted values for given input set
print("in predict")
predict_filtered <- function(mnist.test) {
  test.set.conn <- levels(factor(mnist.test[, "c"]))
  #print(test.set.conn)
  results <- vector(mode="integer", length = nrow(mnist.test))
  for (i in 1: length(test.set.conn)) {
    subset <- mnist.test[mnist.test[, "c"] == test.set.conn[i], ]
    if (is.element(test.set.conn[i], colnames(pcaqda_array))) {
      #print(predict(pcaqda_array[, test.set.conn[i]]$best.model, subset))
      results[mnist.test[, "c"] == test.set.conn[i]] <- predict(pcaqda_array[, test.set.conn[i]]$best.model, subset)$class
    } else {
      results[mnist.test[, "c"] == test.set.conn[i]] <- predict(tn.pcaqda$best.model, subset)$class
    }
  }
  results
}
#plot(tn.pcaqda)

table(actual = mnist.train$y,
      predicted = predict_filtered(mnist.train))

tt <- table(actual = mnist.test$y,
            predicted = predict_filtered(mnist.test))
print(tt)

1 - sum(diag(tt)) / sum(tt)
```

```{r}
prs <- by(mnist.train, mnist.train$y, function(df) {
  pr <- prcomp(~. - y, data = df, scale = FALSE,
               center = TRUE, ncomp = 3)
})
show_digit(prs[["0"]]$rotation[, 1])
show_digit(prs[["1"]]$rotation[, 1])
show_digit(prs[["3"]]$rotation[, 1])
show_digit(prs[["4"]]$rotation[, 1])
show_digit(prs[["7"]]$rotation[, 1])
```
